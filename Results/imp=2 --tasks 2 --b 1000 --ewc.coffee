test_ihm.py --tasks 2 --b 1000 --ewc
---------------------------------------
Testing standard LSTM on IHM dataset...
---------------------------------------

importance = 2

MIMIC training samples: 14681
MIMIC testing samples: 3222
eICU training samples: 50758
eICU testing samples: 10877
Experiment dir: ./exp/Test_ihm
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4851002285629511
Train: epoch: 1, loss = 0.41441458897665145
Train: epoch: 1, loss = 0.3837082549619178
Train: epoch: 1, loss = 0.3669141557998955
Train: epoch: 1, loss = 0.3546643979176879
Train: epoch: 1, loss = 0.3517838672672709
Train: epoch: 1, loss = 0.3457615188083478
Train: epoch: 1, loss = 0.34424976906739174
Train: epoch: 1, loss = 0.3416330585049258
Train:  Epoch 1, Loss=0.34107929252772684, AUC-ROC=0.768759858570229, AUC-PR=0.36200404764320343
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.30609742629276454, AUC-ROC=0.8303904845327557, AUC-PR=0.4827532030582182
Eval task: 2
Eval:  Epoch 1, Loss=0.3239083763095861, AUC-ROC=0.7628829646336236, AUC-PR=0.21831103808857272
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.31473995788022874
Train: epoch: 2, loss = 0.31578000652603805
Train: epoch: 2, loss = 0.31260248926778633
Train: epoch: 2, loss = 0.31412263403180984
Train: epoch: 2, loss = 0.31191623328439894
Train: epoch: 2, loss = 0.3079588823625818
Train: epoch: 2, loss = 0.30876067240456384
Train: epoch: 2, loss = 0.30890337929944506
Train: epoch: 2, loss = 0.31217607876596354
Train:  Epoch 2, Loss=0.31232379998066034, AUC-ROC=0.8132440190052103, AUC-PR=0.4623635628014718
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.30046005531322284, AUC-ROC=0.8363664653542944, AUC-PR=0.5055685570725003
Eval task: 2
Eval:  Epoch 2, Loss=0.3418161713365708, AUC-ROC=0.7514371782978458, AUC-PR=0.19437986360812637
1000
Experiment dir: ./exp/Test_ihm
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.29405815111473205
Train: epoch: 1, loss = 0.26393452792428435
Train: epoch: 1, loss = 0.24920883032803734
Train: epoch: 1, loss = 0.2385161421925295
Train: epoch: 1, loss = 0.23702263684291391
Train: epoch: 1, loss = 0.23218161939720933
Train: epoch: 1, loss = 0.2320090702874586
Train: epoch: 1, loss = 0.22649012105364819
Train: epoch: 1, loss = 0.2263848901503823
Train: epoch: 1, loss = 0.22495952286710963
Train: epoch: 1, loss = 0.22438190699512647
Train: epoch: 1, loss = 0.22349363186280244
Train: epoch: 1, loss = 0.22273138038061846
Train: epoch: 1, loss = 0.22256175150662394
Train: epoch: 1, loss = 0.22144360087470463
Train: epoch: 1, loss = 0.22110719803458778
Train: epoch: 1, loss = 0.21877448263988994
Train: epoch: 1, loss = 0.2194557391326978
Train: epoch: 1, loss = 0.21900058446084394
Train: epoch: 1, loss = 0.2176268064545002
Train: epoch: 1, loss = 0.21594270872107396
Train: epoch: 1, loss = 0.21550859426169403
Train: epoch: 1, loss = 0.21526639517983825
Train: epoch: 1, loss = 0.2149901423997168
Train: epoch: 1, loss = 0.21471159719284624
Train: epoch: 1, loss = 0.21442783250097328
Train: epoch: 1, loss = 0.21484996164993694
Train: epoch: 1, loss = 0.21536666265406113
Train: epoch: 1, loss = 0.21458469405336755
Train: epoch: 1, loss = 0.21380651710415258
Train: epoch: 1, loss = 0.21308493844128304
Train:  Epoch 1, Loss=0.2133182906106991, AUC-ROC=0.8373663937785942, AUC-PR=0.5459304511890679
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3233857576814518, AUC-ROC=0.8228709076180378, AUC-PR=0.4598748098389467
Eval task: 2
Eval:  Epoch 1, Loss=0.18910343392243595, AUC-ROC=0.875630724375902, AUC-PR=0.6468949021425743
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2239719204325229
Train: epoch: 2, loss = 0.20577197722624987
Train: epoch: 2, loss = 0.20110140728453796
Train: epoch: 2, loss = 0.1988823951059021
Train: epoch: 2, loss = 0.1956030416060239
Train: epoch: 2, loss = 0.19593333266675472
Train: epoch: 2, loss = 0.19945004219322332
Train: epoch: 2, loss = 0.19826888631563633
Train: epoch: 2, loss = 0.1992421766753412
Train: epoch: 2, loss = 0.1980369653282687
Train: epoch: 2, loss = 0.19861141118390316
Train: epoch: 2, loss = 0.19890422696325308
Train: epoch: 2, loss = 0.19784890811747083
Train: epoch: 2, loss = 0.1977081355765196
Train: epoch: 2, loss = 0.19821509561749795
Train: epoch: 2, loss = 0.1980838441924425
Train: epoch: 2, loss = 0.19766967995640108
Train: epoch: 2, loss = 0.19829864147998807
Train: epoch: 2, loss = 0.19824326764743186
Train: epoch: 2, loss = 0.1971298469011672
Train: epoch: 2, loss = 0.19663115245866633
Train: epoch: 2, loss = 0.19652742151361466
Train: epoch: 2, loss = 0.19761548132979836
Train: epoch: 2, loss = 0.19731150982222365
Train: epoch: 2, loss = 0.19830296399276703
Train: epoch: 2, loss = 0.19777639753346404
Train: epoch: 2, loss = 0.19827226844598989
Train: epoch: 2, loss = 0.1983037679072004
Train: epoch: 2, loss = 0.1991640938373668
Train: epoch: 2, loss = 0.19882109914409618
Train: epoch: 2, loss = 0.19909037710813385
Train:  Epoch 2, Loss=0.19937299142088435, AUC-ROC=0.8550103710991802, AUC-PR=0.5930374247831997
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.34451601070176735, AUC-ROC=0.818386658060947, AUC-PR=0.44162009093181276
Eval task: 2
Eval:  Epoch 2, Loss=0.18573539338507963, AUC-ROC=0.8855495503123352, AUC-PR=0.6495826552727564